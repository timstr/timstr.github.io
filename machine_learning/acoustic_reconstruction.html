<!DOCTYPE html><html><head><meta charset="UTF-8"><title>Acoustic Reconstruction | Machine Learning | Tim's Portfolio</title><link rel="stylesheet" href="/static/styles.css"><link href="https://fonts.googleapis.com/css?family=Fredoka+One|Signika" rel="stylesheet"></head><body><div id="main"><div class="backdrop"></div><div class="maincontainer"><div class="mainbody"><h1 class="mainheader">Tim's Portfolio</h1><div class="tabmenu" style="background-color: rgb(98, 98, 137)"><div class="tabmenu-list" style="background-color: rgb(98, 98, 137);"><a href="/index.html"><div class="tabmenuitem" style="background-color: rgb(255, 255, 255); filter: brightness(90%);"><span class="tabmenuitem-title">About Me</span></div></a><a href="/machine_learning"><div class="tabmenuitem-active" style="background-color: rgb(255, 255, 255); filter: brightness(100%);"><span class="tabmenuitem-title">Machine Learning</span></div></a><a href="/audio/flosion"><div class="tabmenuitem" style="background-color: rgb(255, 255, 255); filter: brightness(90%);"><span class="tabmenuitem-title">Audio</span></div></a><a href="/graphics/pathtracing/"><div class="tabmenuitem" style="background-color: rgb(255, 255, 255); filter: brightness(90%);"><span class="tabmenuitem-title">Graphics</span></div></a><a href="/physics/rigidbodydynamics/"><div class="tabmenuitem" style="background-color: rgb(255, 255, 255); filter: brightness(90%);"><span class="tabmenuitem-title">Physics</span></div></a><a href="/artwork"><div class="tabmenuitem" style="background-color: rgb(255, 255, 255); filter: brightness(90%);"><span class="tabmenuitem-title">Artwork</span></div></a><a href="/personal"><div class="tabmenuitem" style="background-color: rgb(255, 255, 255); filter: brightness(90%);"><span class="tabmenuitem-title">Personal Stuff</span></div></a></div><div class="tabmenu-list" style="background-color: rgb(255, 255, 255);"><a href="/machine_learning/index.html"><div class="tabmenuitem" style="background-color: rgb(221, 221, 221); filter: brightness(90%);"><span class="tabmenuitem-title">List of Projects</span></div></a><a href="/machine_learning/acoustic_reconstruction.html"><div class="tabmenuitem-active" style="background-color: rgb(221, 221, 221); filter: brightness(100%);"><span class="tabmenuitem-title">Acoustic Reconstruction</span></div></a><a href="/machine_learning/graph_merging.html"><div class="tabmenuitem" style="background-color: rgb(221, 221, 221); filter: brightness(90%);"><span class="tabmenuitem-title">Differentiable Graph Merging</span></div></a><a href="/machine_learning/boneless.html"><div class="tabmenuitem" style="background-color: rgb(221, 221, 221); filter: brightness(90%);"><span class="tabmenuitem-title">Soft-Bodied Locomotion</span></div></a><a href="/machine_learning/hand_gesture_recognition.html"><div class="tabmenuitem" style="background-color: rgb(221, 221, 221); filter: brightness(90%);"><span class="tabmenuitem-title">Hand Gesture Recognition</span></div></a><a href="/machine_learning/hand_gesture_synthesis.html"><div class="tabmenuitem" style="background-color: rgb(221, 221, 221); filter: brightness(90%);"><span class="tabmenuitem-title">Hand Gesture Synthesis</span></div></a></div><div class="tab-content" style="background-color: rgb(221, 221, 221)"><h1>Acoustic Reconstruction using Synthetic Aperture Focusing</h1><h2>Tim Straubinger - October 2021</h2><h3><em>MSc. Thesis</em></h3><img class="bigimage-img" src="/static/img/ml/thesis_system_diagram.png"><div class="section"><div class="section-heading"><div class="section-contents"><h3><em>Abstract</em></h3></div></div><div class="section-body"><div class="section-contents"><p>Navigating and sensing the world through echolocation in air is an innate ability in many animals for which analogous human technologies remain rudimentary. Many engineered approaches to acoustic reconstruction have been devised which typically require unwieldy equipment and a lengthy measurement process, and are largely not applicable in air or in everyday human environments. Recent learning-based approaches to single-emission in-air acoustic reconstruction use simplified hardware and an experimentally-acquired dataset of echoes and the geometry that produced them to train models to predict novel geometry from similar but previously-unheard echoes. However, these learned approaches use spatially-dense representations and attempt to predict an entire scene all at once. Doing so requires a tremendous abundance of training examples in order to learn a model that generalizes, which leaves these techniques vulnerable to over-fitting.</p><p>We introduce an implicit representation for learned in-air acoustic reconstruction inspired by synthetic aperture focusing techniques. Our method trains a neural network to relate the coherency of multiple spatially-separated echo signals, after accounting for the expected time-of-flight along a straight-line path, to the presence or absence of an acoustically reflective object at any sampling location. Additionally, we use signed distance fields to represent geometric predictions which provide a better-behaved training signal and allow for efficient 3D rendering. Using acoustic wave simulation, we show that our method yields better generalization and behaves more intuitively than competing methods while requiring only a small fraction of the amount of training data.</p></div></div></div><div class="section"><div class="section-heading"><div class="section-contents"><h3>Read the Paper</h3></div></div><div class="section-body"><div class="section-contents"><p><a href="/static/papers/ubc_2021_november_straubinger_tim.pdf">Link to paper (.pdf - 2.1 MB)</a></p><p><a href="https://dx.doi.org/10.14288/1.0402577">https://dx.doi.org/10.14288/1.0402577</a></p></div></div></div></div></div></div></div></div></body></html>